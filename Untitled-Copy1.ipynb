{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97339d5",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631523c1",
   "metadata": {},
   "source": [
    "first we will import the net and the tools we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FC import fullyConnectedNN as fc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from experiments import experiment\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b88ce7",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28fe5c",
   "metadata": {},
   "source": [
    "##### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('MNIST-data.npy')\n",
    "y = np.load(\"MNIST-lables.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07643573",
   "metadata": {},
   "source": [
    "##### Prepare the data for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62816dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the features ready for the net\n",
    "labels = np.zeros((len(y), 10))\n",
    "labels[np.arange(len(y)), y] = 1\n",
    "features = X.reshape((X.shape[0], -1))\n",
    "input_dim = len(features[0])\n",
    "output_dim = len(labels[0])\n",
    "\n",
    "# split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# normalize the feature to to the avg of the train\n",
    "mean = np.mean(np.mean(X_train, axis=0))\n",
    "X_train = X_train - mean\n",
    "X_test = X_test - mean\n",
    "\n",
    "# split the test to validation and test\n",
    "X_vladition, X_test, y_vladition, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d06fa",
   "metadata": {},
   "source": [
    "## learning rate and structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156fab39",
   "metadata": {},
   "source": [
    "In this experiments we will try to find the best learning rate for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c938fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07603fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.5, 0.3, 0.1, 0.05, 0.0]\n",
    "structures = [[input_dim, 1024, 1024,  output_dim],\n",
    "             [input_dim, 1024, 256,  output_dim],              \n",
    "             [input_dim, 1024, 512, 256, output_dim], \n",
    "            ]\n",
    "\n",
    "for lr in lrs:\n",
    "    for struct in structures:\n",
    "        exper = experiment(struct, activation='sig', lr=lr, max_epochs=50)\n",
    "        net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "        if score > best_score:\n",
    "            print(\"----------------------new-best-model--------------------------\")\n",
    "            best_struct = struct\n",
    "            best_lr = lr\n",
    "            best_score = score\n",
    "            best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a29be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [0.5, 0.3, 0.1, 0.05, 0.0]\n",
    "structures = [[input_dim, 1024, 1024,  output_dim],\n",
    "             [input_dim, 1024, 256,  output_dim],              \n",
    "             [input_dim, 1024, 512, output_dim], \n",
    "             [input_dim, 512, 512, output_dim], \n",
    "             [input_dim, 512, 256, output_dim],\n",
    "             [input_dim, 2048, output_dim],\n",
    "            ]\n",
    "\n",
    "for lr in lrs:\n",
    "    for struct in structures:\n",
    "        exper = experiment(struct, activation='tan_h', lr=lr, max_epochs=50)\n",
    "        net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "        if score > best_score:\n",
    "            print(\"----------------------new-best-model--------------------------\")\n",
    "            best_struct = struct\n",
    "            best_lr = lr\n",
    "            best_score = score\n",
    "            best_net = net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc188c2f",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e379eb8",
   "metadata": {},
   "source": [
    "In this experiment we will try to find the best regularization coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [10**-4, 10**-3]\n",
    "\n",
    "best_reg1 = 0\n",
    "best_reg2 = 0\n",
    "for reg1 in reg:\n",
    "    for reg2 in reg:\n",
    "        exper = experiment(best_struct, lr=best_lr,l1_reg=reg1, l2_reg=reg2, max_epochs=50)\n",
    "        net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "        if score > best_score:\n",
    "            print(\"----------------------new-best-model--------------------------\")\n",
    "            net.print_net\n",
    "            best_reg1 = reg1\n",
    "            best_reg2 = reg2\n",
    "            best_score = score\n",
    "            best_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [10**-4, 10**-3]\n",
    "\n",
    "best_reg1 = 0\n",
    "best_reg2 = 0\n",
    "for reg1 in reg:\n",
    "    for reg2 in reg:\n",
    "        exper = experiment(best_struct, activation='tan_h', lr=best_lr,l1_reg=reg1, l2_reg=reg2, max_epochs=50)\n",
    "        net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "        if score > best_score:\n",
    "            print(\"----------------------new-best-model--------------------------\")\n",
    "            net.print_net\n",
    "            best_reg1 = reg1\n",
    "            best_reg2 = reg2\n",
    "            best_score = score\n",
    "            best_net = net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bd20b",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f9d15",
   "metadata": {},
   "source": [
    "In this experiment we will try to add momentum to the grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d859e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exper = experiment(best_struct, lr=best_lr,l1_reg=best_reg1, l2_reg=best_reg2, momentum=0.9, max_epochs=50)\n",
    "net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "if score > best_score:\n",
    "    print(\"----------------------new-best-model--------------------------\")\n",
    "    net.print_net\n",
    "    best_reg1 = reg1\n",
    "    best_reg2 = reg2\n",
    "    best_score = score\n",
    "    best_net = net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c5712",
   "metadata": {},
   "source": [
    "## batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992976a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 64, 256]\n",
    "best_batch = 128\n",
    "for batch_size in batch_sizes:\n",
    "    exper = experiment(best_struct, lr=best_lr,l1_reg=best_reg1, l2_reg=best_reg2, momentum=0.9, max_epochs=50, batch_size=batch_size)\n",
    "    net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "    score = net.score(X_vladition, np.argmax(y_vladition, axis=1))\n",
    "    train_score = net.score(X_train, np.argmax(y_train, axis=1))\n",
    "    if score > best_score:\n",
    "        print(\"----------------------new-best-model--------------------------\")\n",
    "        net.print_net\n",
    "        best_batch = batch_size\n",
    "        best_score = score\n",
    "        best_net = net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d96fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 64, 256]\n",
    "best_batch = 128\n",
    "for batch_size in batch_sizes:\n",
    "    net = fc(best_struct, activation='tan_h',l1_reg=best_reg1, l2_reg=best_reg2)\n",
    "    net.train(X_train, y_train, X_vladition, y_vladition, lr=best_lr, epochs = 50, batch_size=batch_size)\n",
    "    score = net.score(X_vladition, np.argmax(y_vladition, axis=1))\n",
    "    train_score = net.score(X_train, np.argmax(y_train, axis=1))\n",
    "    print('--------------------------results------------------------------')\n",
    "    print(f\"validation score={score} train score={train_score}\")\n",
    "    net.print_net()\n",
    "    print('----------------------experiment-over--------------------------')\n",
    "    if score > best_score:\n",
    "        print(\"----------------------new-best-model--------------------------\")\n",
    "        net.print_net\n",
    "        best_batch = batch_size\n",
    "        best_score = score\n",
    "        best_net = net\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846da18",
   "metadata": {},
   "source": [
    "# changing the learning rate during the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ce3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exper = experiment(best_struct, lr=best_lr,l1_reg=best_reg1, l2_reg=best_reg2, max_epochs=50, lr_change=0.9)\n",
    "net, score = exper.run_experiment(X_train, y_train, X_vladition, y_vladition)\n",
    "if score > best_score:\n",
    "    print(\"----------------------new-best-model--------------------------\")\n",
    "    net.print_net\n",
    "    best_score = score\n",
    "    best_net = net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c055ce",
   "metadata": {},
   "source": [
    "# train the best net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.train(X_train, y_train, X_vladition, y_vladition, epochs=50, lr=best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd505141",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.train(X_train, y_train, X_vladition, y_vladition, epochs=50,lr=best_lr*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.train(X_train, y_train, X_vladition, y_vladition, epochs=50, lr=best_lr*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.print_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1351684",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.score(X_test, np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b83da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
